{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Toxicity - bi-LSTMs and 2D Convs - Dec 21st\n",
    "\n",
    "    - 200D Glove embeddings and 30 max sequence length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries and Data Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:08:36.514193Z",
     "iopub.status.busy": "2021-12-03T23:08:36.513837Z",
     "iopub.status.idle": "2021-12-03T23:08:38.160075Z",
     "shell.execute_reply": "2021-12-03T23:08:38.159345Z",
     "shell.execute_reply.started": "2021-12-03T23:08:36.514105Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "\n",
    "import string     # Imports the library\n",
    "import nltk        # Imports the natural language toolkit\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#nltk.download('stopwords')   # Download the stopwords dataset\n",
    "#nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:08:38.163Z",
     "iopub.status.busy": "2021-12-03T23:08:38.162732Z",
     "iopub.status.idle": "2021-12-03T23:08:43.785303Z",
     "shell.execute_reply": "2021-12-03T23:08:43.784444Z",
     "shell.execute_reply.started": "2021-12-03T23:08:38.162971Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "#tfds.list_builders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:08:43.786983Z",
     "iopub.status.busy": "2021-12-03T23:08:43.786682Z",
     "iopub.status.idle": "2021-12-03T23:08:45.767749Z",
     "shell.execute_reply": "2021-12-03T23:08:45.767138Z",
     "shell.execute_reply.started": "2021-12-03T23:08:43.786943Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#df_train_wiki_tox = pd.read_csv(\"../input/jigsaw-toxic-comment-classification-challenge/train.csv\")\n",
    "df_train_wiki_tox = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Pre-trained Glove and Word2Vec embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:08:45.769426Z",
     "iopub.status.busy": "2021-12-03T23:08:45.769089Z",
     "iopub.status.idle": "2021-12-03T23:08:45.962946Z",
     "shell.execute_reply": "2021-12-03T23:08:45.962181Z",
     "shell.execute_reply.started": "2021-12-03T23:08:45.769397Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rober\\anaconda3\\lib\\site-packages\\gensim\\similarities\\__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import os, sys\n",
    "\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from gensim.test.utils import datapath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.21.4'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:08:45.96438Z",
     "iopub.status.busy": "2021-12-03T23:08:45.964163Z",
     "iopub.status.idle": "2021-12-03T23:08:45.967622Z",
     "shell.execute_reply": "2021-12-03T23:08:45.966939Z",
     "shell.execute_reply.started": "2021-12-03T23:08:45.964355Z"
    }
   },
   "outputs": [],
   "source": [
    "# import gensim.downloader as api\n",
    "# info_df = pd.DataFrame.from_dict(api.info()['models'], orient='index')\n",
    "# info_df[['file_size', 'base_dataset', 'parameters']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:08:45.969567Z",
     "iopub.status.busy": "2021-12-03T23:08:45.968903Z",
     "iopub.status.idle": "2021-12-03T23:08:45.9779Z",
     "shell.execute_reply": "2021-12-03T23:08:45.977328Z",
     "shell.execute_reply.started": "2021-12-03T23:08:45.969529Z"
    }
   },
   "outputs": [],
   "source": [
    "#model=api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "#model=api.load(\"glove-twitter-200\")\n",
    "#model=api.load(\"glove-wiki-gigaword-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:08:45.97931Z",
     "iopub.status.busy": "2021-12-03T23:08:45.978769Z",
     "iopub.status.idle": "2021-12-03T23:12:44.212058Z",
     "shell.execute_reply": "2021-12-03T23:12:44.211091Z",
     "shell.execute_reply.started": "2021-12-03T23:08:45.979269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 90.441 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "\n",
    "\n",
    "# Get path to file\n",
    "vector_size = 200\n",
    "\n",
    "glove_file = 'glove.twitter.27B.200d_wv.txt'\n",
    "\n",
    "\n",
    "# Load with gensim\n",
    "model = KeyedVectors.load_word2vec_format(glove_file)\n",
    "#model = KeyedVectors.load(glove_file)\n",
    "\n",
    "t_stop = time.time()\n",
    "print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA and Comment Text Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:12:44.214445Z",
     "iopub.status.busy": "2021-12-03T23:12:44.214022Z",
     "iopub.status.idle": "2021-12-03T23:12:44.269357Z",
     "shell.execute_reply": "2021-12-03T23:12:44.268315Z",
     "shell.execute_reply.started": "2021-12-03T23:12:44.214391Z"
    }
   },
   "outputs": [],
   "source": [
    "def text_process_1(text):\n",
    "    #text=text.decode('utf-8')\n",
    "    \n",
    "    # Replace the xa0 with a space\n",
    "    text=text.replace('xa0',' ')\n",
    "    # Replace the \\xa0 with a space\n",
    "    text=text.replace('\\xa0',' ')\n",
    "    # Replace the \\n\\n with a space\n",
    "    text=text.replace('\\n\\n',' ')\n",
    "    # Replace the \\n with a space\n",
    "    text=text.replace('\\n',' ')\n",
    "    # Replace apostrophes with nothing\n",
    "    text=text.replace('\\'','')\n",
    "    # Replace http with a space\n",
    "    text=text.replace('http','')\n",
    "    \n",
    "    # Replace hyphens with a space\n",
    "    text=text.replace('-','')\n",
    "    \n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    \n",
    "    cleaned_words=[w.lower() for w in tokens if w.isalnum()]\n",
    "    #remove any words that are actually digits. \n",
    "    no_integers = [x for x in cleaned_words if not (x.isdigit() or x[0] == '-' and x[1:].isdigit())]\n",
    "    \n",
    "    \n",
    "    # The code for removing stopwords\n",
    "    stoplist = stopwords.words('english') \n",
    "    stoplist = set(stoplist)\n",
    "    \n",
    "    No_StopWords = [word for word in no_integers if word.lower() not in stoplist ]\n",
    "    \n",
    "    No_StopWords = ' '.join(No_StopWords)\n",
    "    \n",
    "    return No_StopWords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:12:44.271153Z",
     "iopub.status.busy": "2021-12-03T23:12:44.270923Z",
     "iopub.status.idle": "2021-12-03T23:14:24.573606Z",
     "shell.execute_reply": "2021-12-03T23:14:24.572568Z",
     "shell.execute_reply.started": "2021-12-03T23:12:44.271124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 88.756 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "\n",
    "df_train_wiki_tox['clean']=df_train_wiki_tox['comment_text'].apply(lambda x: text_process_1(x))\n",
    "\n",
    "\n",
    "t_stop = time.time()\n",
    "print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:14:24.578323Z",
     "iopub.status.busy": "2021-12-03T23:14:24.577762Z",
     "iopub.status.idle": "2021-12-03T23:14:24.61012Z",
     "shell.execute_reply": "2021-12-03T23:14:24.609485Z",
     "shell.execute_reply.started": "2021-12-03T23:14:24.578257Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>daww matches background colour im seemingly st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man im really trying edit war guy constant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cant make real suggestions improvement wondere...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page thats</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "0             0        0       0       0              0   \n",
       "1             0        0       0       0              0   \n",
       "2             0        0       0       0              0   \n",
       "3             0        0       0       0              0   \n",
       "4             0        0       0       0              0   \n",
       "\n",
       "                                               clean  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  daww matches background colour im seemingly st...  \n",
       "2  hey man im really trying edit war guy constant...  \n",
       "3  cant make real suggestions improvement wondere...  \n",
       "4                sir hero chance remember page thats  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_wiki_tox.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_wiki_tox.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:14:24.628396Z",
     "iopub.status.busy": "2021-12-03T23:14:24.628162Z",
     "iopub.status.idle": "2021-12-03T23:14:24.633828Z",
     "shell.execute_reply": "2021-12-03T23:14:24.633021Z",
     "shell.execute_reply.started": "2021-12-03T23:14:24.628364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'daww matches background colour im seemingly stuck thanks talk january utc'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_wiki_tox['clean'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153968"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(1,df_train_wiki_tox.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print 10 Random Non-Toxic Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_non_tox = df_train_wiki_tox[df_train_wiki_tox['toxic']==0]\n",
    "# df_non_tox = df_non_tox.reset_index()\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "    \n",
    "#     n=random.randint(1,df_non_tox.shape[0])\n",
    "#     print(n)\n",
    "#     orig_cmt = df_non_tox['comment_text'][n]\n",
    "#     rnd_cmt = df_non_tox['clean'][n]\n",
    "#     print(rnd_cmt)\n",
    "#     print('...')\n",
    "#     print(orig_cmt)\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_toxic = df_train_wiki_tox[df_train_wiki_tox['toxic']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_toxic['comment_text'][6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print 10 Random Toxic Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tox = df_train_wiki_tox[df_train_wiki_tox['toxic']==1]\n",
    "# df_tox = df_tox.reset_index()\n",
    "\n",
    "\n",
    "# for i in range(10):\n",
    "    \n",
    "#     n=random.randint(1,df_tox.shape[0])\n",
    "#     print(n)\n",
    "#     orig_cmt = df_tox['comment_text'][n]\n",
    "#     rnd_cmt = df_tox['clean'][n]\n",
    "#     print(rnd_cmt)\n",
    "#     print('...')\n",
    "#     print(orig_cmt)\n",
    "#     print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Final Training Data set of comments greater than 5 words and less than 300 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:14:36.521775Z",
     "iopub.status.busy": "2021-12-03T23:14:36.52147Z",
     "iopub.status.idle": "2021-12-03T23:15:22.237711Z",
     "shell.execute_reply": "2021-12-03T23:15:22.236822Z",
     "shell.execute_reply.started": "2021-12-03T23:14:36.521742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 20.094 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "\n",
    "df_train_wiki_tox['wd_len']=df_train_wiki_tox['clean'].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "\n",
    "\n",
    "\n",
    "t_stop = time.time()\n",
    "print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:15:37.987851Z",
     "iopub.status.busy": "2021-12-03T23:15:37.987557Z",
     "iopub.status.idle": "2021-12-03T23:15:38.082198Z",
     "shell.execute_reply": "2021-12-03T23:15:38.081453Z",
     "shell.execute_reply.started": "2021-12-03T23:15:37.987816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    106708\n",
       "1      1290\n",
       "Name: severe_toxic, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small = df_train_wiki_tox[(df_train_wiki_tox['wd_len']<30) & (df_train_wiki_tox['wd_len']>=1)]\n",
    "df_small=df_small.reset_index()\n",
    "df_small.pop('index')\n",
    "df_small['severe_toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:15:40.684085Z",
     "iopub.status.busy": "2021-12-03T23:15:40.683427Z",
     "iopub.status.idle": "2021-12-03T23:15:40.707953Z",
     "shell.execute_reply": "2021-12-03T23:15:40.70729Z",
     "shell.execute_reply.started": "2021-12-03T23:15:40.684046Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    106708\n",
       "1      1290\n",
       "Name: new_severe_toxic, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "# instatiate sklearn's labelencoder\n",
    "le = preprocessing.LabelEncoder()\n",
    "\n",
    "# fit label encorder and return encoded integer labels for categorical string features\n",
    "df_small['new_severe_toxic'] = le.fit_transform(df_small['severe_toxic'].values)\n",
    "df_small['new_severe_toxic'].value_counts()\n",
    "#df_3.pop('Results')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:15:42.918978Z",
     "iopub.status.busy": "2021-12-03T23:15:42.918699Z",
     "iopub.status.idle": "2021-12-03T23:15:42.932149Z",
     "shell.execute_reply": "2021-12-03T23:15:42.931525Z",
     "shell.execute_reply.started": "2021-12-03T23:15:42.918945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    95803\n",
       "1    12195\n",
       "Name: new_toxic, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit label encorder and return encoded integer labels for categorical string features\n",
    "df_small['new_toxic'] = le.fit_transform(df_small['toxic'].values)\n",
    "df_small['new_toxic'].value_counts()\n",
    "#df_3.pop('Results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Look at those toxic comments with less than 5 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "      <th>clean</th>\n",
       "      <th>wd_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0002bcb3da6cb337</td>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>cocksucker piss around work</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>0086998b34865f93</td>\n",
       "      <td>Fuck you, block me, you faggot pussy!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fuck block faggot pussy</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>00ab65775c601cf9</td>\n",
       "      <td>Atheism is full of bias shit</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>atheism full bias shit</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>01113aece2e95a73</td>\n",
       "      <td>Be careful who you call a moron.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>careful call moron</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>01208d2b76624130</td>\n",
       "      <td>Hi \\n\\nIm a fucking bitch.\\n\\n50.180.208.181</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>hi im fucking bitch</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159394</th>\n",
       "      <td>fcf5a6ad5918f164</td>\n",
       "      <td>your boring \\n\\nand retarded two</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>boring retarded two</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159448</th>\n",
       "      <td>fdc92e571d39e7e1</td>\n",
       "      <td>Yeah i no it sucks.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>yeah sucks</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159449</th>\n",
       "      <td>fdce660ddcd6d7ca</td>\n",
       "      <td>I think he is a gay fag!!!</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>think gay fag</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159493</th>\n",
       "      <td>fef142420a215b90</td>\n",
       "      <td>FUCKING FAGGOT \\n\\nLOLWAT.</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>fucking faggot lolwat</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159514</th>\n",
       "      <td>ff39a2895fc3b40e</td>\n",
       "      <td>YOU ARE A MISCHIEVIOUS PUBIC HAIR</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>mischievious pubic hair</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2372 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id                                  comment_text  toxic  \\\n",
       "6       0002bcb3da6cb337  COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1   \n",
       "211     0086998b34865f93         Fuck you, block me, you faggot pussy!      1   \n",
       "268     00ab65775c601cf9                  Atheism is full of bias shit      1   \n",
       "423     01113aece2e95a73              Be careful who you call a moron.      1   \n",
       "442     01208d2b76624130  Hi \\n\\nIm a fucking bitch.\\n\\n50.180.208.181      1   \n",
       "...                  ...                                           ...    ...   \n",
       "159394  fcf5a6ad5918f164              your boring \\n\\nand retarded two      1   \n",
       "159448  fdc92e571d39e7e1                           Yeah i no it sucks.      1   \n",
       "159449  fdce660ddcd6d7ca                    I think he is a gay fag!!!      1   \n",
       "159493  fef142420a215b90                    FUCKING FAGGOT \\n\\nLOLWAT.      1   \n",
       "159514  ff39a2895fc3b40e             YOU ARE A MISCHIEVIOUS PUBIC HAIR      1   \n",
       "\n",
       "        severe_toxic  obscene  threat  insult  identity_hate  \\\n",
       "6                  1        1       0       1              0   \n",
       "211                0        1       0       1              0   \n",
       "268                0        0       0       0              0   \n",
       "423                0        0       0       0              0   \n",
       "442                1        1       0       1              0   \n",
       "...              ...      ...     ...     ...            ...   \n",
       "159394             0        0       0       0              0   \n",
       "159448             0        0       0       0              0   \n",
       "159449             0        0       0       0              1   \n",
       "159493             0        1       0       1              0   \n",
       "159514             0        0       0       1              0   \n",
       "\n",
       "                              clean  wd_len  \n",
       "6       cocksucker piss around work       4  \n",
       "211         fuck block faggot pussy       4  \n",
       "268          atheism full bias shit       4  \n",
       "423              careful call moron       3  \n",
       "442             hi im fucking bitch       4  \n",
       "...                             ...     ...  \n",
       "159394          boring retarded two       3  \n",
       "159448                   yeah sucks       2  \n",
       "159449                think gay fag       3  \n",
       "159493        fucking faggot lolwat       3  \n",
       "159514      mischievious pubic hair       3  \n",
       "\n",
       "[2372 rows x 10 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_wiki_tox[(df_train_wiki_tox['wd_len']<=4) & (df_train_wiki_tox['toxic']==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distribution plot of word Lengths by Toxicity Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:15:47.237062Z",
     "iopub.status.busy": "2021-12-03T23:15:47.236249Z",
     "iopub.status.idle": "2021-12-03T23:15:48.439139Z",
     "shell.execute_reply": "2021-12-03T23:15:48.438326Z",
     "shell.execute_reply.started": "2021-12-03T23:15:47.237016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x133049e3b50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 417.5x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.displot(df_small, x=\"wd_len\", hue=\"new_toxic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First check to see if the words in the sentence also exist in the Glove Model\n",
    "    - replace any words not found in Glove with 'bland'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:15:50.72152Z",
     "iopub.status.busy": "2021-12-03T23:15:50.721185Z",
     "iopub.status.idle": "2021-12-03T23:15:50.726561Z",
     "shell.execute_reply": "2021-12-03T23:15:50.725595Z",
     "shell.execute_reply.started": "2021-12-03T23:15:50.721485Z"
    }
   },
   "outputs": [],
   "source": [
    "def word_replacer(sent):\n",
    "    sent_list = [x if x in model.key_to_index else 'bland' for x in sent.split(' ')] \n",
    "    sentence = ' '.join(sent_list)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:15:53.89095Z",
     "iopub.status.busy": "2021-12-03T23:15:53.890312Z",
     "iopub.status.idle": "2021-12-03T23:15:53.89685Z",
     "shell.execute_reply": "2021-12-03T23:15:53.895924Z",
     "shell.execute_reply.started": "2021-12-03T23:15:53.89091Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bland'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc='asdfsadfasdfs'\n",
    "word_replacer(cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:15:55.347061Z",
     "iopub.status.busy": "2021-12-03T23:15:55.346777Z",
     "iopub.status.idle": "2021-12-03T23:15:57.67516Z",
     "shell.execute_reply": "2021-12-03T23:15:57.674137Z",
     "shell.execute_reply.started": "2021-12-03T23:15:55.347029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.311 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "\n",
    "df_small['clean_w2v']=df_small['clean'].apply(lambda x: word_replacer(x))\n",
    "\n",
    "t_stop = time.time()\n",
    "print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For sentences less than 70 words, padd the input by repeating words until length of 70 is reached "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:16:09.422847Z",
     "iopub.status.busy": "2021-12-03T23:16:09.422558Z",
     "iopub.status.idle": "2021-12-03T23:16:09.427675Z",
     "shell.execute_reply": "2021-12-03T23:16:09.42713Z",
     "shell.execute_reply.started": "2021-12-03T23:16:09.42281Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_padder(a):\n",
    "    b=a.split(' ')\n",
    "    c=b\n",
    "    seq_len=31\n",
    "    missing_len_idx = seq_len-len(b)-1\n",
    "\n",
    "    for m in range(missing_len_idx):\n",
    "        c.append(b[m])\n",
    "        \n",
    "    d = ' '.join(c)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:16:13.52889Z",
     "iopub.status.busy": "2021-12-03T23:16:13.528593Z",
     "iopub.status.idle": "2021-12-03T23:16:13.535067Z",
     "shell.execute_reply": "2021-12-03T23:16:13.534515Z",
     "shell.execute_reply.started": "2021-12-03T23:16:13.528858Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'real vagina real photo vagina gone would mind make new one vagina picture indonesians vagina love'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small['clean_w2v'][666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:16:15.68359Z",
     "iopub.status.busy": "2021-12-03T23:16:15.68261Z",
     "iopub.status.idle": "2021-12-03T23:16:15.689368Z",
     "shell.execute_reply": "2021-12-03T23:16:15.688675Z",
     "shell.execute_reply.started": "2021-12-03T23:16:15.683556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'real vagina real photo vagina gone would mind make new one vagina picture indonesians vagina love real vagina real photo vagina gone would mind make new one vagina picture indonesians'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_padder(df_small['clean_w2v'][666])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:16:17.170921Z",
     "iopub.status.busy": "2021-12-03T23:16:17.170171Z",
     "iopub.status.idle": "2021-12-03T23:16:18.06249Z",
     "shell.execute_reply": "2021-12-03T23:16:18.061386Z",
     "shell.execute_reply.started": "2021-12-03T23:16:17.170885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.232 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "\n",
    "df_small['clean_w2v_padding']=df_small['clean_w2v'].apply(lambda x: sentence_padder(x))\n",
    "\n",
    "t_stop = time.time()\n",
    "print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check word lengths of padded sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:16:19.237477Z",
     "iopub.status.busy": "2021-12-03T23:16:19.237166Z",
     "iopub.status.idle": "2021-12-03T23:16:58.978332Z",
     "shell.execute_reply": "2021-12-03T23:16:58.977437Z",
     "shell.execute_reply.started": "2021-12-03T23:16:19.237448Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 11.426 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "\n",
    "df_small['w2v_padding_wd_len']=df_small['clean_w2v_padding'].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "\n",
    "t_stop = time.time()\n",
    "print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:16:58.980555Z",
     "iopub.status.busy": "2021-12-03T23:16:58.980155Z",
     "iopub.status.idle": "2021-12-03T23:16:58.993776Z",
     "shell.execute_reply": "2021-12-03T23:16:58.99296Z",
     "shell.execute_reply.started": "2021-12-03T23:16:58.980512Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30    107998\n",
       "Name: w2v_padding_wd_len, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small['w2v_padding_wd_len'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For sentences greater than 30 words, truncate the input so its only 70 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:17:38.845174Z",
     "iopub.status.busy": "2021-12-03T23:17:38.844859Z",
     "iopub.status.idle": "2021-12-03T23:17:38.850049Z",
     "shell.execute_reply": "2021-12-03T23:17:38.849116Z",
     "shell.execute_reply.started": "2021-12-03T23:17:38.84514Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentence_shortener(testt):\n",
    "    testt2=testt.split(' ')\n",
    "    testt3=testt2[0:30]\n",
    "    testt4 = ' '.join(testt3)\n",
    "    return testt4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:17:45.572908Z",
     "iopub.status.busy": "2021-12-03T23:17:45.572647Z",
     "iopub.status.idle": "2021-12-03T23:17:46.31243Z",
     "shell.execute_reply": "2021-12-03T23:17:46.311494Z",
     "shell.execute_reply.started": "2021-12-03T23:17:45.572881Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 0.176 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "\n",
    "df_small['clean_w2v_padding_2']=df_small['clean_w2v_padding'].apply(lambda x: sentence_shortener(x))\n",
    "\n",
    "t_stop = time.time()\n",
    "print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check word lengths of truncated sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:17:47.532515Z",
     "iopub.status.busy": "2021-12-03T23:17:47.532193Z",
     "iopub.status.idle": "2021-12-03T23:18:16.441527Z",
     "shell.execute_reply": "2021-12-03T23:18:16.440571Z",
     "shell.execute_reply.started": "2021-12-03T23:17:47.532481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 11.493 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "\n",
    "df_small['w2v_padding_wd_len_2']=df_small['clean_w2v_padding_2'].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "\n",
    "t_stop = time.time()\n",
    "print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:18:16.443346Z",
     "iopub.status.busy": "2021-12-03T23:18:16.443027Z",
     "iopub.status.idle": "2021-12-03T23:18:16.453711Z",
     "shell.execute_reply": "2021-12-03T23:18:16.452816Z",
     "shell.execute_reply.started": "2021-12-03T23:18:16.443309Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30    107998\n",
       "Name: w2v_padding_wd_len_2, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small['w2v_padding_wd_len_2'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toxic Comments Classification - Under Sample Majority Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:18:16.455392Z",
     "iopub.status.busy": "2021-12-03T23:18:16.455118Z",
     "iopub.status.idle": "2021-12-03T23:18:16.70684Z",
     "shell.execute_reply": "2021-12-03T23:18:16.706118Z",
     "shell.execute_reply.started": "2021-12-03T23:18:16.455361Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rober\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:587: FutureWarning: Pass sampling_strategy=0.5 as keyword args. From version 0.9 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "# define undersample strategy\n",
    "undersample = RandomUnderSampler(.5)\n",
    "\n",
    "#undersample_2 = RandomUnderSampler(sampling_strategy='majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:18:16.709098Z",
     "iopub.status.busy": "2021-12-03T23:18:16.708849Z",
     "iopub.status.idle": "2021-12-03T23:18:16.764357Z",
     "shell.execute_reply": "2021-12-03T23:18:16.763593Z",
     "shell.execute_reply.started": "2021-12-03T23:18:16.70907Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/53723928/attributeerror-series-object-has-no-attribute-reshape\n",
    "X=df_small['clean_w2v_padding_2']\n",
    "X=X.values.reshape(-1, 1)\n",
    "\n",
    "Y=df_small['new_toxic']\n",
    "Y=Y.values.reshape(-1, 1)\n",
    "\n",
    "X_under, y_under = undersample.fit_resample(X, Y)\n",
    "new_x=pd.DataFrame(X_under)[0]\n",
    "new_y=pd.DataFrame(y_under)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Severely Toxic Comments Classification - Under Sample Majority Class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:19:11.266934Z",
     "iopub.status.busy": "2021-12-03T23:19:11.266112Z",
     "iopub.status.idle": "2021-12-03T23:19:11.314477Z",
     "shell.execute_reply": "2021-12-03T23:19:11.313736Z",
     "shell.execute_reply.started": "2021-12-03T23:19:11.266886Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_2=df_small['clean_w2v_padding_2']\n",
    "# X_2=X_2.values.reshape(-1, 1)\n",
    "\n",
    "# Y_2=df_small['new_severe_toxic']\n",
    "# Y_2=Y_2.values.reshape(-1, 1)\n",
    "\n",
    "# X_under_2, y_under_2 = undersample_2.fit_resample(X_2, Y_2)\n",
    "# new_x_2=pd.DataFrame(X_under_2)[0]\n",
    "# new_y_2=pd.DataFrame(y_under_2)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Attempt to create Sentence Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create 30-dim Sentence Vector for each comment by looking up word in Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:19:14.463667Z",
     "iopub.status.busy": "2021-12-03T23:19:14.463403Z",
     "iopub.status.idle": "2021-12-03T23:19:14.46854Z",
     "shell.execute_reply": "2021-12-03T23:19:14.467657Z",
     "shell.execute_reply.started": "2021-12-03T23:19:14.46364Z"
    }
   },
   "outputs": [],
   "source": [
    "#convert each token in sentence into a 768 Glove Vector\n",
    "def sent_vectorizer_1(text):\n",
    "    sent_vector = [model[x] for x in text.split(' ') if x in model.key_to_index] \n",
    "    return sent_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:19:16.814485Z",
     "iopub.status.busy": "2021-12-03T23:19:16.813676Z",
     "iopub.status.idle": "2021-12-03T23:19:16.820804Z",
     "shell.execute_reply": "2021-12-03T23:19:16.819992Z",
     "shell.execute_reply.started": "2021-12-03T23:19:16.814435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36585"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:19:18.49851Z",
     "iopub.status.busy": "2021-12-03T23:19:18.498185Z",
     "iopub.status.idle": "2021-12-03T23:19:18.504225Z",
     "shell.execute_reply": "2021-12-03T23:19:18.503511Z",
     "shell.execute_reply.started": "2021-12-03T23:19:18.498473Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'defamation dont know bland bland habitual liar lie documented many places example defamation dont know bland bland habitual liar lie documented many places example defamation dont know bland bland habitual'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:19:20.535794Z",
     "iopub.status.busy": "2021-12-03T23:19:20.535031Z",
     "iopub.status.idle": "2021-12-03T23:19:20.541714Z",
     "shell.execute_reply": "2021-12-03T23:19:20.540931Z",
     "shell.execute_reply.started": "2021-12-03T23:19:20.535757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gave permission insult religious organisation using wikipedia source gave permission insult religious organisation using wikipedia source gave permission insult religious organisation using wikipedia source gave permission insult religious organisation using'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_x[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:19:22.947384Z",
     "iopub.status.busy": "2021-12-03T23:19:22.947091Z",
     "iopub.status.idle": "2021-12-03T23:19:22.953764Z",
     "shell.execute_reply": "2021-12-03T23:19:22.953128Z",
     "shell.execute_reply.started": "2021-12-03T23:19:22.947352Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdx=new_x[5]\n",
    "sent_tensor=sent_vectorizer_1(sdx)\n",
    "len(sent_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:19:25.274556Z",
     "iopub.status.busy": "2021-12-03T23:19:25.27426Z",
     "iopub.status.idle": "2021-12-03T23:19:25.280108Z",
     "shell.execute_reply": "2021-12-03T23:19:25.279337Z",
     "shell.execute_reply.started": "2021-12-03T23:19:25.274525Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent_tensor[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Tensor - Toxic Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-03T23:19:32.29123Z",
     "iopub.status.busy": "2021-12-03T23:19:32.290945Z",
     "iopub.status.idle": "2021-12-03T23:19:34.237148Z",
     "shell.execute_reply": "2021-12-03T23:19:34.236327Z",
     "shell.execute_reply.started": "2021-12-03T23:19:32.291195Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time elapsed: 1.271 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t_start = time.time()\n",
    "\n",
    "tox_sentences_traindata = []\n",
    "for i in range(len(new_x)):\n",
    "    tox_sentences_traindata.append(sent_vectorizer_1(new_x[i]))\n",
    "#traindata = tf.convert_to_tensor(traindata)\n",
    "\n",
    "t_stop = time.time()\n",
    "print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_tensor_sentences_traindata = tf.convert_to_tensor(tox_sentences_traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "        ..\n",
       "36580    1\n",
       "36581    1\n",
       "36582    1\n",
       "36583    1\n",
       "36584    1\n",
       "Name: 0, Length: 36585, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Vector - Severley Toxic Comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# t_start = time.time()\n",
    "\n",
    "# sev_tox_sentences_traindata = []\n",
    "# for i in range(len(new_x_2)):\n",
    "#     sev_tox_sentences_traindata.append(sent_vectorizer_1(new_x_2[i]))\n",
    "# #traindata = tf.convert_to_tensor(traindata)\n",
    "\n",
    "# t_stop = time.time()\n",
    "# print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sev_tox_tensor_sentences_traindata = tf.convert_to_tensor(sev_tox_sentences_traindata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_y_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Tensor and Y labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([36585, 30, 200])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tox_tensor_sentences_traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sev_tox_tensor_sentences_traindata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox_tensor_y_labels = tf.convert_to_tensor(new_y)\n",
    "#sev_tox_tensor_y_labels = tf.convert_to_tensor(new_y_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([36585])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tox_tensor_y_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sev_tox_tensor_y_labels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### import necessary tools and models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:11.725495Z",
     "iopub.status.busy": "2021-12-02T15:38:11.725097Z",
     "iopub.status.idle": "2021-12-02T15:38:13.562415Z",
     "shell.execute_reply": "2021-12-02T15:38:13.561464Z",
     "shell.execute_reply.started": "2021-12-02T15:38:11.725448Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "import tensorflow\n",
    "\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.constraints import MaxNorm\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "import numpy as np\n",
    "\n",
    "from keras.layers.convolutional import Conv1D, MaxPooling1D\n",
    "\n",
    "\n",
    "import keras.utils\n",
    "from keras import utils as np_utils\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, GRU, Convolution1D, Flatten, LeakyReLU\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, GlobalAveragePooling1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import SpatialDropout1D, MaxPooling1D, Bidirectional, GRU, concatenate\n",
    "\n",
    "\n",
    "# import necessary tools and models \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import sklearn.model_selection as cv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "from keras.regularizers import l2, l1_l2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test split for Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:13.563735Z",
     "iopub.status.busy": "2021-12-02T15:38:13.563525Z",
     "iopub.status.idle": "2021-12-02T15:38:13.57087Z",
     "shell.execute_reply": "2021-12-02T15:38:13.570041Z",
     "shell.execute_reply.started": "2021-12-02T15:38:13.563709Z"
    }
   },
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/41859605/split-tensor-into-training-and-test-sets\n",
    "\n",
    "def train_test_split_tensors(X, y, **options):\n",
    "    \"\"\"\n",
    "    encapsulation for the sklearn.model_selection.train_test_split function\n",
    "    in order to split tensors objects and return tensors as output\n",
    "\n",
    "    :param X: tensorflow.Tensor object\n",
    "    :param y: tensorflow.Tensor object\n",
    "    :dict **options: typical sklearn options are available, such as test_size and train_size\n",
    "    \"\"\"\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X.numpy(), y.numpy(), **options)\n",
    "\n",
    "    X_train, X_test = tf.constant(X_train), tf.constant(X_test)\n",
    "    y_train, y_test = tf.constant(y_train), tf.constant(y_test)\n",
    "\n",
    "    del(train_test_split)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:13.573047Z",
     "iopub.status.busy": "2021-12-02T15:38:13.572419Z",
     "iopub.status.idle": "2021-12-02T15:38:15.253991Z",
     "shell.execute_reply": "2021-12-02T15:38:15.253084Z",
     "shell.execute_reply.started": "2021-12-02T15:38:13.573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Regular Toxic - separate train - test data\n",
    "X_train, X_test, y_train, y_test = train_test_split_tensors(tox_tensor_sentences_traindata, \n",
    "                                                            tox_tensor_y_labels, test_size=.3, random_state=69)\n",
    "\n",
    "# # Severely Toxic - separate train - test data \n",
    "# sv_X_train, sv_X_test, sv_y_train, sv_y_test = train_test_split_tensors(sev_tox_tensor_sentences_traindata, \n",
    "#                                                             sev_tox_tensor_y_labels, test_size=.3, random_state=69)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle the Test Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tox_x_test'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(X_test,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tox_y_test'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(y_test,outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delete original Tensors prior to Train / Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tox_tensor_y_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tox_tensor_sentences_traindata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropout() layer possibly drops time steps too"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/50720670/using-dropout-with-keras-and-lstm-gru-cell\n",
    "\n",
    "https://stackoverflow.com/questions/49940280/keras-lstm-dropout-vs-recurrent-dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Recurrent Regularizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/53656220/how-to-add-recurrent-dropout-to-cudnngru-or-cudnnlstm-in-keras\n",
    "\n",
    "https://stackoverflow.com/questions/61931629/overfitting-in-lstm-even-after-using-regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compile and Train Model for Regular Toxicity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:15.256053Z",
     "iopub.status.busy": "2021-12-02T15:38:15.255634Z",
     "iopub.status.idle": "2021-12-02T15:38:15.261793Z",
     "shell.execute_reply": "2021-12-02T15:38:15.260692Z",
     "shell.execute_reply.started": "2021-12-02T15:38:15.255932Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fit model\n",
    "epochs = 200\n",
    "batch_size=32\n",
    "#early_stopping_monitor = EarlyStopping(patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:15.26378Z",
     "iopub.status.busy": "2021-12-02T15:38:15.263412Z",
     "iopub.status.idle": "2021-12-02T15:38:15.276205Z",
     "shell.execute_reply": "2021-12-02T15:38:15.275317Z",
     "shell.execute_reply.started": "2021-12-02T15:38:15.263726Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([25609, 30, 200])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:15.27909Z",
     "iopub.status.busy": "2021-12-02T15:38:15.278122Z",
     "iopub.status.idle": "2021-12-02T15:38:15.372243Z",
     "shell.execute_reply": "2021-12-02T15:38:15.371319Z",
     "shell.execute_reply.started": "2021-12-02T15:38:15.279041Z"
    }
   },
   "outputs": [],
   "source": [
    "# create and fit the LSTM network\n",
    "DL_model = Sequential()\n",
    "DL_model.add(SpatialDropout1D(0.2))\n",
    "\n",
    "# DL_model.add((LSTM(128, return_sequences=True, kernel_regularizer=l2(0.00021), \n",
    "#                                 recurrent_regularizer=l2(0.00021), input_shape=(70,200))))\n",
    "DL_model.add(Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.00021), \n",
    "                                recurrent_regularizer=l2(0.00021), input_shape=(30,200))))\n",
    "DL_model.add(Dropout(0.2))\n",
    "\n",
    "#Conv2D needs 4 dims - batch size, width, height, and number of channels\n",
    "#DL_model.add(Conv2D(128, 5, 2, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "\n",
    "DL_model.add(tf.keras.layers.Reshape((30, 256, 1), input_shape=(30, 256)))\n",
    "\n",
    "DL_model.add(Conv2D(filters=128, \n",
    "                       kernel_size=(5,2), \n",
    "                       input_shape=(30, 256, 1), \n",
    "                       activation=\"relu\"))\n",
    "\n",
    "# DL_model.add(MaxPooling1D(2))\n",
    "DL_model.add(Dropout(.2))\n",
    "DL_model.add(Flatten())\n",
    "#DL_model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "DL_model.add(Dense(256, activation=\"relu\"))\n",
    "DL_model.add(Dropout(.4))\n",
    "DL_model.add(Dense(128, activation=\"relu\"))\n",
    "DL_model.add(Dropout(.4))\n",
    "DL_model.add(Dense(10, activation=\"relu\"))\n",
    "DL_model.add(Dropout(.4))\n",
    "DL_model.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:15.373703Z",
     "iopub.status.busy": "2021-12-02T15:38:15.373478Z",
     "iopub.status.idle": "2021-12-02T15:38:15.377718Z",
     "shell.execute_reply": "2021-12-02T15:38:15.376585Z",
     "shell.execute_reply.started": "2021-12-02T15:38:15.373676Z"
    }
   },
   "outputs": [],
   "source": [
    "#DL_model.compile(loss='mean_squared_error', optimizer='adam',metrics=['accuracy'])\n",
    "DL_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:15.379579Z",
     "iopub.status.busy": "2021-12-02T15:38:15.379223Z",
     "iopub.status.idle": "2021-12-02T15:38:15.406821Z",
     "shell.execute_reply": "2021-12-02T15:38:15.406118Z",
     "shell.execute_reply.started": "2021-12-02T15:38:15.379548Z"
    }
   },
   "outputs": [],
   "source": [
    "DL_model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:15.409071Z",
     "iopub.status.busy": "2021-12-02T15:38:15.408543Z",
     "iopub.status.idle": "2021-12-02T15:38:15.412495Z",
     "shell.execute_reply": "2021-12-02T15:38:15.411801Z",
     "shell.execute_reply.started": "2021-12-02T15:38:15.409029Z"
    }
   },
   "outputs": [],
   "source": [
    "#DL_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train bi-LSTM and 2D Conv Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:15.414271Z",
     "iopub.status.busy": "2021-12-02T15:38:15.413629Z",
     "iopub.status.idle": "2021-12-02T15:38:15.434589Z",
     "shell.execute_reply": "2021-12-02T15:38:15.433451Z",
     "shell.execute_reply.started": "2021-12-02T15:38:15.414236Z"
    }
   },
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', min_delta=0, patience=5),\n",
    "    ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.4f}.h5'),\n",
    "    TensorBoard(log_dir='logs'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:38:15.437175Z",
     "iopub.status.busy": "2021-12-02T15:38:15.436492Z",
     "iopub.status.idle": "2021-12-02T15:49:01.496887Z",
     "shell.execute_reply": "2021-12-02T15:49:01.495922Z",
     "shell.execute_reply.started": "2021-12-02T15:38:15.437124Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "641/641 [==============================] - 51s 50ms/step - loss: 0.4534 - accuracy: 0.8480 - val_loss: 0.3061 - val_accuracy: 0.9157\n",
      "Epoch 2/100\n",
      "641/641 [==============================] - 31s 48ms/step - loss: 0.3035 - accuracy: 0.9034 - val_loss: 0.2766 - val_accuracy: 0.9162\n",
      "Epoch 3/100\n",
      "641/641 [==============================] - 31s 48ms/step - loss: 0.2749 - accuracy: 0.9094 - val_loss: 0.2637 - val_accuracy: 0.9147\n",
      "Epoch 4/100\n",
      "641/641 [==============================] - 31s 48ms/step - loss: 0.2597 - accuracy: 0.9150 - val_loss: 0.2422 - val_accuracy: 0.9194\n",
      "Epoch 5/100\n",
      "641/641 [==============================] - 31s 48ms/step - loss: 0.2527 - accuracy: 0.9163 - val_loss: 0.2633 - val_accuracy: 0.9174\n",
      "Epoch 6/100\n",
      "641/641 [==============================] - 31s 48ms/step - loss: 0.2444 - accuracy: 0.9202 - val_loss: 0.2495 - val_accuracy: 0.9196\n",
      "Epoch 7/100\n",
      "641/641 [==============================] - 31s 48ms/step - loss: 0.2383 - accuracy: 0.9273 - val_loss: 0.2591 - val_accuracy: 0.9172\n",
      "Epoch 8/100\n",
      "641/641 [==============================] - 31s 48ms/step - loss: 0.2285 - accuracy: 0.9270 - val_loss: 0.2594 - val_accuracy: 0.9143\n",
      "Epoch 9/100\n",
      "641/641 [==============================] - 31s 48ms/step - loss: 0.2244 - accuracy: 0.9332 - val_loss: 0.2759 - val_accuracy: 0.9170\n"
     ]
    }
   ],
   "source": [
    "history = DL_model.fit(X_train, y_train, \n",
    "                       epochs=100, batch_size=32,\n",
    "                       validation_split=0.2, callbacks=my_callbacks,\n",
    "                      )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Best Model Back In and evaluate against Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tox_x_test'\n",
    "infile = open(filename,'rb')\n",
    "X_test = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'tox_y_test'\n",
    "infile = open(filename,'rb')\n",
    "y_test = pickle.load(infile)\n",
    "infile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:49:01.498544Z",
     "iopub.status.busy": "2021-12-02T15:49:01.498327Z",
     "iopub.status.idle": "2021-12-02T15:49:49.352737Z",
     "shell.execute_reply": "2021-12-02T15:49:49.351907Z",
     "shell.execute_reply.started": "2021-12-02T15:49:01.498516Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "343/343 [==============================] - 6s 9ms/step - loss: 0.2370 - accuracy: 0.9206\n",
      "Test result: 92.065 loss: 0.237\n"
     ]
    }
   ],
   "source": [
    "#testing - to free GPU Memory - kernel must be restarted after loading each new Model \n",
    "\n",
    "#DL_model = keras.models.load_model('model.06-0.2495.h5')\n",
    "# 343/343 [==============================] - 7s 9ms/step - loss: 0.2434 - accuracy: 0.9193\n",
    "# Test result: 91.928 loss: 0.243\n",
    "DL_model = keras.models.load_model('model.04-0.2422.h5')\n",
    "\n",
    "# 343/343 [==============================] - 6s 9ms/step - loss: 0.2370 - accuracy: 0.9206\n",
    "# Test result: 92.065 loss: 0.237\n",
    "\n",
    "scores = DL_model.evaluate(X_test, y_test, batch_size=32, verbose=1)\n",
    "print('Test result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:49:49.354181Z",
     "iopub.status.busy": "2021-12-02T15:49:49.353912Z",
     "iopub.status.idle": "2021-12-02T15:49:50.349013Z",
     "shell.execute_reply": "2021-12-02T15:49:50.34798Z",
     "shell.execute_reply.started": "2021-12-02T15:49:49.35415Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(221)\n",
    "\n",
    "plt.figure(0)\n",
    "plt.plot(history.history['accuracy'],'r')\n",
    "plt.plot(history.history['val_accuracy'],'g')\n",
    "plt.xticks(np.arange(0, 51, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "plt.legend(['train','validation'])\n",
    " \n",
    " \n",
    "plt.figure(1)\n",
    "plt.plot(history.history['loss'],'r')\n",
    "plt.plot(history.history['val_loss'],'g')\n",
    "plt.xticks(np.arange(0, 51, 2.0))\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "plt.legend(['train','validation'])\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and Train Model for Severe Toxicity \n",
    "    \n",
    "    - Severe Toxicity more explicit to identify, probably don't need LSTM models to identify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:49:50.350909Z",
     "iopub.status.busy": "2021-12-02T15:49:50.350575Z",
     "iopub.status.idle": "2021-12-02T15:49:50.356297Z",
     "shell.execute_reply": "2021-12-02T15:49:50.355093Z",
     "shell.execute_reply.started": "2021-12-02T15:49:50.350867Z"
    }
   },
   "outputs": [],
   "source": [
    "# #Fit model\n",
    "# epochs_2 = 200\n",
    "# batch_size_2 =32\n",
    "# early_stopping_monitor_2 = EarlyStopping(patience=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:49:50.358334Z",
     "iopub.status.busy": "2021-12-02T15:49:50.357735Z",
     "iopub.status.idle": "2021-12-02T15:49:50.371217Z",
     "shell.execute_reply": "2021-12-02T15:49:50.370271Z",
     "shell.execute_reply.started": "2021-12-02T15:49:50.358228Z"
    }
   },
   "outputs": [],
   "source": [
    "# sv_X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:49:50.373833Z",
     "iopub.status.busy": "2021-12-02T15:49:50.372887Z",
     "iopub.status.idle": "2021-12-02T15:49:50.420875Z",
     "shell.execute_reply": "2021-12-02T15:49:50.419945Z",
     "shell.execute_reply.started": "2021-12-02T15:49:50.373786Z"
    }
   },
   "outputs": [],
   "source": [
    "# # create and fit the LSTM network\n",
    "# DL_model_2 = Sequential()\n",
    "# DL_model_2.add(SpatialDropout1D(0.2))\n",
    "# #DL_model_2.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout(.3),kernel_regularizer=l2(0.0001), recurrent_regularizer=l2(0.0001), input_shape=(100,512))))\n",
    "# DL_model_2.add(Bidirectional(LSTM(128, return_sequences=True, kernel_regularizer=l2(0.00021), recurrent_regularizer=l2(0.00021), input_shape=(100,300))))\n",
    "# DL_model_2.add(SpatialDropout1D(0.3))\n",
    "\n",
    "# DL_model_2.add(Conv1D(128, 5, 2, activation = 'relu', kernel_initializer = 'he_uniform'))\n",
    "\n",
    "# DL_model_2.add(MaxPooling1D(2))\n",
    "# DL_model_2.add(Dropout(.3))\n",
    "# DL_model_2.add(Flatten())\n",
    "# DL_model_2.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# DL_model_2.add(Dense(256, activation=\"relu\"))\n",
    "# DL_model_2.add(Dropout(.4))\n",
    "# DL_model_2.add(Dense(128, activation=\"relu\"))\n",
    "# DL_model_2.add(Dropout(.4))\n",
    "# DL_model_2.add(Dense(10, activation=\"relu\"))\n",
    "# DL_model_2.add(Dropout(.4))\n",
    "# DL_model_2.add(Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:49:50.422783Z",
     "iopub.status.busy": "2021-12-02T15:49:50.422466Z",
     "iopub.status.idle": "2021-12-02T15:49:50.435099Z",
     "shell.execute_reply": "2021-12-02T15:49:50.434041Z",
     "shell.execute_reply.started": "2021-12-02T15:49:50.422742Z"
    }
   },
   "outputs": [],
   "source": [
    "# DL_model_2.compile(loss=keras.losses.binary_crossentropy,\n",
    "#               optimizer=tensorflow.keras.optimizers.Adam(),\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:49:50.436875Z",
     "iopub.status.busy": "2021-12-02T15:49:50.436347Z",
     "iopub.status.idle": "2021-12-02T15:49:50.444462Z",
     "shell.execute_reply": "2021-12-02T15:49:50.443508Z",
     "shell.execute_reply.started": "2021-12-02T15:49:50.436835Z"
    }
   },
   "outputs": [],
   "source": [
    "# DL_model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:49:50.446721Z",
     "iopub.status.busy": "2021-12-02T15:49:50.446116Z",
     "iopub.status.idle": "2021-12-02T15:49:50.459771Z",
     "shell.execute_reply": "2021-12-02T15:49:50.458885Z",
     "shell.execute_reply.started": "2021-12-02T15:49:50.446675Z"
    }
   },
   "outputs": [],
   "source": [
    "# my_callbacks_2 = [\n",
    "#     EarlyStopping(monitor='val_loss', min_delta=0, patience=5),\n",
    "#     ModelCheckpoint(filepath='model.{epoch:02d}-{val_loss:.2f}.h5'),\n",
    "#     TensorBoard(log_dir='logs'),\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:49:50.462173Z",
     "iopub.status.busy": "2021-12-02T15:49:50.461408Z",
     "iopub.status.idle": "2021-12-02T15:50:26.783057Z",
     "shell.execute_reply": "2021-12-02T15:50:26.782361Z",
     "shell.execute_reply.started": "2021-12-02T15:49:50.462126Z"
    }
   },
   "outputs": [],
   "source": [
    "# # #train model\n",
    "# history_2 = DL_model_2.fit(sv_X_train, sv_y_train, \n",
    "#                        epochs=100, batch_size=32,\n",
    "#                        validation_split=0.2, callbacks=my_callbacks_2,\n",
    "#                        workers=14,\n",
    "#                        use_multiprocessing=True\n",
    "#                       )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:50:26.785166Z",
     "iopub.status.busy": "2021-12-02T15:50:26.784629Z",
     "iopub.status.idle": "2021-12-02T15:50:29.423573Z",
     "shell.execute_reply": "2021-12-02T15:50:29.423014Z",
     "shell.execute_reply.started": "2021-12-02T15:50:26.785122Z"
    }
   },
   "outputs": [],
   "source": [
    "# # #testing\n",
    "# scores_2 = DL_model_2.evaluate(sv_X_test, sv_y_test, batch_size=32, verbose=1)\n",
    "# print('Test result: %.3f loss: %.3f' % (scores_2[1]*100,scores_2[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:50:29.424976Z",
     "iopub.status.busy": "2021-12-02T15:50:29.424754Z",
     "iopub.status.idle": "2021-12-02T15:50:29.428307Z",
     "shell.execute_reply": "2021-12-02T15:50:29.427501Z",
     "shell.execute_reply.started": "2021-12-02T15:50:29.424929Z"
    }
   },
   "outputs": [],
   "source": [
    "# #save model to disk\n",
    "# model_json = DL_model_2.to_json()\n",
    "# with open('model_ann_severe_toxic.json', 'w') as json_file:\n",
    "#     json_file.write(model_json)\n",
    "# DL_model_2.save_weights('model_ann_severe_toxic.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:50:29.429884Z",
     "iopub.status.busy": "2021-12-02T15:50:29.429548Z",
     "iopub.status.idle": "2021-12-02T15:50:30.078164Z",
     "shell.execute_reply": "2021-12-02T15:50:30.077172Z",
     "shell.execute_reply.started": "2021-12-02T15:50:29.429855Z"
    }
   },
   "outputs": [],
   "source": [
    "# plt.figure(221)\n",
    "\n",
    "# plt.figure(0)\n",
    "# plt.plot(history_2.history['accuracy'],'r')\n",
    "# plt.plot(history_2.history['val_accuracy'],'g')\n",
    "# plt.xticks(np.arange(0, 101, 2.0))\n",
    "# plt.rcParams['figure.figsize'] = (12, 4)\n",
    "# plt.xlabel(\"Num of Epochs\")\n",
    "# plt.ylabel(\"Accuracy\")\n",
    "# plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "# plt.legend(['train','validation'])\n",
    " \n",
    " \n",
    "# #plt.figure(1)\n",
    "# plt.plot(history_2.history['loss'],'r')\n",
    "# plt.plot(history_2.history['val_loss'],'g')\n",
    "# plt.xticks(np.arange(0, 101, 2.0))\n",
    "# plt.rcParams['figure.figsize'] = (12, 4)\n",
    "# plt.xlabel(\"Num of Epochs\")\n",
    "# plt.ylabel(\"Loss\")\n",
    "# plt.title(\"Training Loss vs Validation Loss\")\n",
    "# plt.legend(['train','validation'])\n",
    " \n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Data Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:50:30.079705Z",
     "iopub.status.busy": "2021-12-02T15:50:30.07948Z",
     "iopub.status.idle": "2021-12-02T15:50:30.210456Z",
     "shell.execute_reply": "2021-12-02T15:50:30.209833Z",
     "shell.execute_reply.started": "2021-12-02T15:50:30.079676Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_test = pd.read_csv('../input/jigsaw-toxic-severity-rating/comments_to_score.csv',low_memory = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:50:30.212464Z",
     "iopub.status.busy": "2021-12-02T15:50:30.211819Z",
     "iopub.status.idle": "2021-12-02T15:50:39.454204Z",
     "shell.execute_reply": "2021-12-02T15:50:39.453585Z",
     "shell.execute_reply.started": "2021-12-02T15:50:30.212426Z"
    }
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# t_start = time.time()\n",
    "\n",
    "# df_test['clean']=df_test['text'].apply(lambda x: text_process_1(x))\n",
    "\n",
    "\n",
    "# t_stop = time.time()\n",
    "# print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:50:39.456042Z",
     "iopub.status.busy": "2021-12-02T15:50:39.45555Z",
     "iopub.status.idle": "2021-12-02T15:50:49.480389Z",
     "shell.execute_reply": "2021-12-02T15:50:49.47954Z",
     "shell.execute_reply.started": "2021-12-02T15:50:39.456006Z"
    }
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# t_start = time.time()\n",
    "# df_test['clean_w2v']=df_test['clean'].apply(lambda x: word_replacer(x))\n",
    "# df_test['clean_w2v_padding']=df_test['clean_w2v'].apply(lambda x: sentence_padder(x))\n",
    "# df_test['clean_w2v']=df_test['clean'].apply(lambda x: word_replacer(x))\n",
    "# df_test['w2v_padding_wd_len']=df_test['clean_w2v_padding'].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "\n",
    "# df_test['clean_w2v_padding_2']=df_test['clean_w2v_padding'].apply(lambda x: sentence_shortener(x))\n",
    "# df_test['w2v_padding_wd_len_2']=df_test['clean_w2v_padding_2'].apply(lambda x: len(nltk.word_tokenize(x)))\n",
    "\n",
    "# t_stop = time.time()\n",
    "# print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:50:49.482548Z",
     "iopub.status.busy": "2021-12-02T15:50:49.482044Z",
     "iopub.status.idle": "2021-12-02T15:50:50.509975Z",
     "shell.execute_reply": "2021-12-02T15:50:50.509024Z",
     "shell.execute_reply.started": "2021-12-02T15:50:49.482496Z"
    }
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# t_start = time.time()\n",
    "\n",
    "# sentences_test = []\n",
    "# for i in range(len(pd.Series(df_test['clean_w2v_padding_2']))):\n",
    "#     sentences_test.append(sent_vectorizer_1(pd.Series(df_test['clean_w2v_padding_2'])[i]))\n",
    "# #traindata = tf.convert_to_tensor(traindata)\n",
    "\n",
    "# t_stop = time.time()\n",
    "# print('Time elapsed: {:.3f} seconds'.format(t_stop - t_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:50:50.51168Z",
     "iopub.status.busy": "2021-12-02T15:50:50.511421Z",
     "iopub.status.idle": "2021-12-02T15:51:16.383113Z",
     "shell.execute_reply": "2021-12-02T15:51:16.382266Z",
     "shell.execute_reply.started": "2021-12-02T15:50:50.511648Z"
    }
   },
   "outputs": [],
   "source": [
    "# tensor_sentences_traindata = tf.convert_to_tensor(sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:51:16.390185Z",
     "iopub.status.busy": "2021-12-02T15:51:16.389905Z",
     "iopub.status.idle": "2021-12-02T15:51:16.395657Z",
     "shell.execute_reply": "2021-12-02T15:51:16.39443Z",
     "shell.execute_reply.started": "2021-12-02T15:51:16.390147Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_ids=df_test['comment_id']\n",
    "# tensor_y_test = tf.convert_to_tensor(test_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Severe Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:51:16.397258Z",
     "iopub.status.busy": "2021-12-02T15:51:16.397017Z",
     "iopub.status.idle": "2021-12-02T15:51:25.908385Z",
     "shell.execute_reply": "2021-12-02T15:51:25.907415Z",
     "shell.execute_reply.started": "2021-12-02T15:51:16.397229Z"
    }
   },
   "outputs": [],
   "source": [
    "# Y_test_pred_Sev_tox=DL_model_2.predict(tensor_sentences_traindata)\n",
    "# Y_test_pred_Sev_tox_2=pd.DataFrame(Y_test_pred_Sev_tox)\n",
    "# Y_test_pred_Sev_tox_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Regular Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:51:25.911883Z",
     "iopub.status.busy": "2021-12-02T15:51:25.911268Z",
     "iopub.status.idle": "2021-12-02T15:51:34.100774Z",
     "shell.execute_reply": "2021-12-02T15:51:34.100159Z",
     "shell.execute_reply.started": "2021-12-02T15:51:25.911842Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_test_pred_reg_tox=DL_model.predict(tensor_sentences_traindata)\n",
    "Y_test_pred_reg_tox_2=pd.DataFrame(Y_test_pred_reg_tox)\n",
    "Y_test_pred_reg_tox_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add Regular and Severe Toxicity together for final ranking score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:51:34.102114Z",
     "iopub.status.busy": "2021-12-02T15:51:34.101778Z",
     "iopub.status.idle": "2021-12-02T15:51:34.119023Z",
     "shell.execute_reply": "2021-12-02T15:51:34.118178Z",
     "shell.execute_reply.started": "2021-12-02T15:51:34.102085Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_merge=pd.concat([test_ids, Y_test_pred_reg_tox_2, Y_test_pred_Sev_tox_2], axis=1)\n",
    "# df_merge.columns=[\"comment_id\",\"b\",\"d\"]\n",
    "\n",
    "# df_merge['score']=df_merge['b']+df_merge['d']\n",
    "# df_merge.pop('b')\n",
    "# df_merge.pop('d')\n",
    "# df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:51:34.121119Z",
     "iopub.status.busy": "2021-12-02T15:51:34.120612Z",
     "iopub.status.idle": "2021-12-02T15:51:34.125025Z",
     "shell.execute_reply": "2021-12-02T15:51:34.12421Z",
     "shell.execute_reply.started": "2021-12-02T15:51:34.121068Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_merge=pd.concat([test_ids, Y_test_pred_reg_tox_2], axis=1)\n",
    "# df_merge.columns=[\"comment_id\",\"b\"]\n",
    "\n",
    "# df_merge['score']=df_merge['b']\n",
    "# df_merge.pop('b')\n",
    "# #df_merge.pop('d')\n",
    "# df_merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-02T15:51:34.126977Z",
     "iopub.status.busy": "2021-12-02T15:51:34.126491Z",
     "iopub.status.idle": "2021-12-02T15:51:34.168841Z",
     "shell.execute_reply": "2021-12-02T15:51:34.167916Z",
     "shell.execute_reply.started": "2021-12-02T15:51:34.126907Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_merge.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
